import requests
import streamlit as st
from langchain.tools import DuckDuckGoSearchRun
import PyPDF2
from docx import Document
import chardet
import base64
from openai import OpenAI

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def initialize_session_state():
    state_defaults = {
        "messages": [],
        "search_enabled": False,
        "file_analyzed": False,
        "file_content": "",
        "file_summary": "",
        "selected_model": "è±†åŒ…",
        "selected_function": "æ™ºèƒ½é—®ç­”",
        "api_keys": {}
    }
    for key, value in state_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# é¡µé¢é…ç½®
st.set_page_config(page_title="å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹", layout="wide")
initialize_session_state()

# ====================
# æ ¸å¿ƒåŠŸèƒ½å®ç°
# ====================
def call_model_api(prompt, model_type, uploaded_file=None):
    """ç»Ÿä¸€æ¨¡å‹è°ƒç”¨æ¥å£"""
    headers = {"Content-Type": "application/json"}
    params = {}

    try:
        if model_type == "DeepSeek-V3":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['DeepSeek']}"
            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",
                json={
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯DeepSeek-V3ï¼Œç”±æ­å·æ·±åº¦æ±‚ç´¢äººå·¥æ™ºèƒ½åŸºç¡€æŠ€æœ¯ç ”ç©¶æœ‰é™å…¬å¸å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›ç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›ç­”ã€‚DeepSeekä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "è±†åŒ…":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['è±†åŒ…']}"
            response = requests.post(
                "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
                json={
                    "model": "ep-20250128163906-p4tb5",
                    "messages": [
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "é€šä¹‰åƒé—®":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['é€šä¹‰åƒé—®']}"
            response = requests.post(
                "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                json={
                    "model": "qwen-plus",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "æ–‡å¿ƒä¸€è¨€":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['æ–‡å¿ƒä¸€è¨€']}"
            response = requests.post(
                "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions",
                json={
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "æ™ºè°±æ¸…è¨€":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['æ™ºè°±æ¸…è¨€']}"
            response = requests.post(
                "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                json={
                    "model": "glm-4",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "MiniMax":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['MiniMax']}"
            response = requests.post(
                "https://api.minimax.chat/v1/text/chatcompletion_v2",
                json={
                    "model": "abab5.5-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "Kimi(è§†è§‰ç†è§£)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['Kimi(è§†è§‰ç†è§£)']}"
            response = requests.post(
                "https://api.moonshot.cn/v1/chat/completions",
                json={
                    "model": "moonshot-v1-8k",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯Kimiï¼Œç”±Moonshot AIæä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›ç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›ç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "GPTs(èŠå¤©ã€è¯­éŸ³è¯†åˆ«)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                json={
                    "model": "gpt-4o",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "DALL-E(æ–‡ç”Ÿå›¾)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            response = requests.post(
                "https://api.openai.com/v1/images/generations",
                json={
                    "prompt": prompt,
                    "n": 1,
                    "size": "512x512"
                },
                headers=headers
            )
            response_json = response.json()
            if "data" in response_json and len(response_json["data"]) > 0:
                image_url = response_json["data"][0]["url"]
                return image_url
            else:
                st.error(f"DALL-E API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None

        elif model_type == "moonshot-v1-8k-vision-preview":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['Kimi(è§†è§‰ç†è§£)']}"
            encoded_string = base64.b64encode(prompt).decode("utf-8")
            response = requests.post(
                "https://api.moonshot.cn/v1/chat/completions",
                json={
                    "model": "moonshot-v1-8k-vision-preview",
                    "messages": [
                        {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_string}"}}]}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "DeepSeek-R1(æ·±åº¦æ¨ç†)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['DeepSeek']}"
            response = requests.post(
                "https://api.deepseek.com/chat/completions",
                json={
                    "model": "deepseek-reasoner",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸ªæ“…é•¿æ·±åº¦æ¨ç†çš„äººå·¥æ™ºèƒ½æ¨¡å‹DeepSeek-R1ï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„é€»è¾‘å’Œæ•°å­¦é—®é¢˜ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "stream": False
                },
                headers=headers
            )
            return handle_response(response)

        elif model_type == "o1(æ·±åº¦æ¨ç†)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                json={
                    "model": "o1-mini",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_completion_tokens": max_tokens  # ä¿ç•™ max_completion_tokens å‚æ•°
                },
                headers=headers
            )
            response_json = response.json()
            if "choices" in response_json:
                return response_json["choices"][0]["message"]["content"]
            else:
                st.error(f"o1 API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None

    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return None

def handle_response(response):
    """å¤„ç† API å“åº”"""
    try:
        if response.status_code == 200:
            response_json = response.json()
            if "choices" in response_json and len(response_json["choices"]) > 0:
                return response_json["choices"][0]["message"]["content"]
            else:
                st.error(f"API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None
        elif response.status_code == 503:
            st.error("æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚")
            return None
        else:
            st.error(f"API è¯·æ±‚å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{response.status_code}")
            return None
    except ValueError:
        st.error("æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚")
        return None

def handle_file_upload(uploaded_file):
    """å¤„ç†ä¸Šä¼ æ–‡ä»¶å¹¶è¿”å›å†…å®¹"""
    file_type = uploaded_file.name.split(".")[-1].lower()
    try:
        if file_type in ["txt", "pdf", "docx"]:
            if file_type == "txt":
                raw_data = uploaded_file.getvalue()
                encoding = chardet.detect(raw_data)["encoding"]
                return raw_data.decode(encoding)
            elif file_type == "pdf":
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                return "\n".join([page.extract_text() for page in pdf_reader.pages])
            elif file_type == "docx":
                doc = Document(uploaded_file)
                return "\n".join([para.text for para in doc.paragraphs])
        elif file_type in ["jpg", "jpeg", "png"]:
            return uploaded_file.getvalue()
        elif file_type in ["mp3", "wav", "m4a", "mp4", "webm"]:
            return uploaded_file
    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        return None

def perform_visual_analysis(image_content):
    """ä½¿ç”¨ moonshot-v1-8k-vision-preview æ¨¡å‹è¿›è¡Œè§†è§‰åˆ†æ"""
    try:
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {st.session_state.api_keys['Kimi(è§†è§‰ç†è§£)']}"}
        encoded_string = base64.b64encode(image_content).decode("utf-8")
        response = requests.post(
            "https://api.moonshot.cn/v1/chat/completions",
            json={
                "model": "moonshot-v1-8k-vision-preview",
                "messages": [
                    {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_string}"}}]}
                ],
                "temperature": temperature,
                "max_tokens": max_tokens
            },
            headers=headers
        )
        return handle_response(response)
    except Exception as e:
        st.error(f"è§†è§‰åˆ†æå¤±è´¥: {str(e)}")
        return None

# ====================
# ä¾§è¾¹æ é…ç½®
# ====================
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    # API å¯†é’¥ç®¡ç†
    st.subheader("APIå¯†é’¥ç®¡ç†")
    api_key_input = st.text_input(
        "è¾“å…¥ API å¯†é’¥",
        help="è¾“å…¥ä¸€ä¸ªAPIå¯†é’¥ï¼Œç”¨äºè®¿é—®æ‰€é€‰æ¨¡å‹",
        type="password"
    )
    if api_key_input:
        st.session_state.api_keys = {
            "è±†åŒ…": api_key_input,
            "Kimi(è§†è§‰ç†è§£)": api_key_input,
            "DeepSeek": api_key_input,
            "é€šä¹‰åƒé—®": api_key_input,
            "æ–‡å¿ƒä¸€è¨€": api_key_input,
            "æ™ºè°±æ¸…è¨€": api_key_input,
            "MiniMax": api_key_input,
            "OpenAI": api_key_input
        }
        st.success("API å¯†é’¥å·²ä¿å­˜ï¼")

    # æ¨¡å‹é€‰æ‹©
    model_options = {
        "è±†åŒ…": ["ep-20250128163906-p4tb5"],
        "DeepSeek-V3": ["deepseek-chat"],
        "é€šä¹‰åƒé—®": ["qwen-plus"],
        "æ–‡å¿ƒä¸€è¨€": ["ERNIE-Bot"],
        "æ™ºè°±æ¸…è¨€": ["glm-4"],
        "MiniMax": ["abab5.5-chat"],
        "DALL-E(æ–‡ç”Ÿå›¾)": ["dall-e-3"],
        "DeepSeek-R1(æ·±åº¦æ¨ç†)": ["deepseek-reasoner"],
        "o1(æ·±åº¦æ¨ç†)": ["o1-mini"],
        "Kimi(è§†è§‰ç†è§£)": ["moonshot-v1-8k-vision-preview"],
        "GPTs(èŠå¤©ã€è¯­éŸ³è¯†åˆ«)": ["gpt-4o"]
    }

    st.session_state.selected_model = st.selectbox(
        "é€‰æ‹©å¤§æ¨¡å‹",
        list(model_options.keys()),
        index=0
    )

    # åŠŸèƒ½é€‰æ‹©
    function_options = [
        "æ™ºèƒ½é—®ç­”",
        "æ–‡æœ¬ç¿»è¯‘",
        "æ–‡æœ¬æ€»ç»“",
        "æ–‡ç”Ÿå›¾",
        "æ·±åº¦æ¨ç†",
        "è§†è§‰ç†è§£",
        "è¯­éŸ³è¯†åˆ«"
    ]
    st.session_state.selected_function = st.selectbox(
        "é€‰æ‹©åŠŸèƒ½",
        function_options,
        index=0
    )

    # é€šç”¨å‚æ•°
    col1, col2 = st.columns(2)
    with col1:
        temperature = st.slider("åˆ›æ„åº¦", 0.0, 1.0, 0.5, 0.1)
    with col2:
        max_tokens = st.slider("å“åº”é•¿åº¦", 100, 4096, 2048, 100)

    # API æµ‹è¯•åŠŸèƒ½
    st.subheader("API æµ‹è¯•")
    if st.button("ğŸ” æµ‹è¯• API è¿æ¥"):
        if not st.session_state.api_keys:
            st.error("è¯·å…ˆè¾“å…¥ API å¯†é’¥ï¼")
        else:
            with st.spinner("æ­£åœ¨æµ‹è¯• API è¿æ¥..."):
                try:
                    test_prompt = "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'ã€‚"
                    response = call_model_api(test_prompt, st.session_state.selected_model)
                    if response:
                        st.success(f"API è¿æ¥æˆåŠŸï¼æ¨¡å‹å›å¤ï¼š{response}")
                    else:
                        st.error("API è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥å’Œç½‘ç»œè®¾ç½®ã€‚")
                except Exception as e:
                    st.error(f"API æµ‹è¯•å¤±è´¥ï¼š{str(e)}")

    if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = []
        st.rerun()

    # æ›´æ–°è¯´æ˜
    st.subheader("æ›´æ–°è¯´æ˜")
    st.write("- æ–°å¢: `DeepSeek-R1` æ¨¡å‹æ”¯æŒ")
    st.write("- é¢„å‘Šï¼šåç»­å°†å¢åŠ æ„å»ºç§äººçŸ¥è¯†åº“(RAG)åŠŸèƒ½")

# ====================
# ä¸»ç•Œé¢å¸ƒå±€
# ====================
st.title("ğŸ¤– å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader(
    "ğŸ“ ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒæ–‡æœ¬/PDF/Word/å›¾ç‰‡/éŸ³é¢‘ï¼‰",
    type=["txt", "pdf", "docx", "doc", "jpg", "jpeg", "png", "mp3", "wav", "m4a", "mp4", "webm"],
    key="file_uploader"
)

# å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜åˆ° session_state ä¸­
if uploaded_file:
    st.session_state.uploaded_file = uploaded_file
    st.session_state.file_content = handle_file_upload(uploaded_file)
    if st.session_state.file_content:
        st.session_state.file_analyzed = True

        # è‡ªåŠ¨æ‰§è¡Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½
        if uploaded_file.name.split(".")[-1].lower() in ["mp3", "wav", "m4a", "mp4", "webm"]:
            try:
                client = OpenAI(api_key=st.session_state.api_keys["OpenAI"])
                transcription = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=st.session_state.file_content
                )
                st.write("è¯­éŸ³è¯†åˆ«ç»“æœï¼š")
                st.write(transcription.text)
                st.session_state.file_summary = transcription.text
            except Exception as e:
                st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        elif uploaded_file.name.split(".")[-1].lower() in ["jpg", "jpeg", "png"]:
            analysis_result = perform_visual_analysis(st.session_state.file_content)
            st.write("è§†è§‰åˆ†æç»“æœï¼š")
            st.write(analysis_result)
        else:
            summary_prompt = f"è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ€»ç»“å’Œæ¢³ç†ï¼Œæå–æ ¸å¿ƒå†…å®¹ï¼š\n{st.session_state.file_content}"
            summary_response = call_model_api(summary_prompt, st.session_state.selected_model)
            if summary_response:
                st.session_state.file_summary = summary_response
                st.write("æ–‡ä»¶æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š")
                st.write(st.session_state.file_summary)

# åŠŸèƒ½æ“ä½œåŒº
with st.container():
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button(
            "ğŸŒ è”ç½‘æœç´¢[" + ("on" if st.session_state.search_enabled else "off") + "]",
            use_container_width=True
        ):
            st.session_state.search_enabled = not st.session_state.search_enabled
            st.rerun()

# ç”¨æˆ·é—®é¢˜è¾“å…¥æ 
with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤...", key="user_input")

# åˆå§‹åŒ– DuckDuckGo æœç´¢å·¥å…·
search_tool = DuckDuckGoSearchRun()
def perform_web_search(query):
    try:
        search_results = search_tool.run(query)
        return search_results
    except Exception as e:
        st.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
        return "æ— æ³•è·å–ç½‘ç»œæœç´¢ç»“æœ"

# ====================
# äº¤äº’å¤„ç†é€»è¾‘
# ====================
if uploaded_file:
    st.session_state.file_content = handle_file_upload(uploaded_file)
    if st.session_state.file_content:
        st.session_state.file_analyzed = True

        if uploaded_file.name.split(".")[-1].lower() in ["jpg", "jpeg", "png"]:
            analysis_result = perform_visual_analysis(st.session_state.file_content)
            st.write("è§†è§‰åˆ†æç»“æœï¼š")
            st.write(analysis_result)
        elif uploaded_file.name.split(".")[-1].lower() in ["mp3", "wav", "m4a", "mp4", "webm"]:
            if st.session_state.selected_function == "è¯­éŸ³è¯†åˆ«":
                try:
                    client = OpenAI(api_key=st.session_state.api_keys["OpenAI"])
                    transcription = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=st.session_state.file_content
                    )
                    st.write("è¯­éŸ³è¯†åˆ«ç»“æœï¼š")
                    st.write(transcription.text)
                except Exception as e:
                    st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        else:
            summary_prompt = f"è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ€»ç»“å’Œæ¢³ç†ï¼Œæå–æ ¸å¿ƒå†…å®¹ï¼š\n{st.session_state.file_content}"
            summary_response = call_model_api(summary_prompt, st.session_state.selected_model)
            if summary_response:
                st.session_state.file_summary = summary_response
                st.write("æ–‡ä»¶æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š")
                st.write(st.session_state.file_summary)

if user_input:
    full_prompt = f"{user_input}\n{st.session_state.file_summary}"

    with st.spinner("ğŸ§  æ­£åœ¨å¤„ç†è¯·æ±‚..."):
        if st.session_state.selected_function == "æ–‡ç”Ÿå›¾":
            image_url = call_model_api(full_prompt, "DALL-E(æ–‡ç”Ÿå›¾)")
            st.image(image_url, caption="ç”Ÿæˆç»“æœ")

        elif st.session_state.selected_function == "è§†è§‰ç†è§£":
            if uploaded_file and uploaded_file.name.split(".")[-1].lower() in ["jpg", "jpeg", "png"]:
                analysis_result = perform_visual_analysis(st.session_state.file_content)
                st.write("è§†è§‰åˆ†æç»“æœï¼š")
                st.write(analysis_result)
            else:
                st.error("è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶è¿›è¡Œè§†è§‰ç†è§£åˆ†æã€‚")

        elif st.session_state.selected_function == "æ·±åº¦æ¨ç†":
            if st.session_state.selected_model in ["DeepSeek-R1(æ·±åº¦æ¨ç†)", "o1(æ·±åº¦æ¨ç†)"]:
                response_text = call_model_api(full_prompt, st.session_state.selected_model)
                st.write(response_text)
            else:
                st.error("å½“å‰æ¨¡å‹ä¸æ”¯æŒæ·±åº¦æ¨ç†åŠŸèƒ½ï¼Œè¯·é€‰æ‹©æ”¯æŒè¯¥åŠŸèƒ½çš„æ¨¡å‹ã€‚")

        else:
            if st.session_state.search_enabled:
                search_results = perform_web_search(user_input)
                full_prompt = f"{full_prompt}\nã€ç½‘ç»œæœç´¢ç»“æœã€‘\n{search_results}"

            response = call_model_api(full_prompt, st.session_state.selected_model)
            st.session_state.messages.append({
                "role": "assistant",
                "content": response,
                "type": "text"
            })

# ====================
# å¯¹è¯å†å²å±•ç¤º
# ====================
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg.get("type") == "image":
            st.image(msg["content"])
        else:
            st.write(msg["content"])

# åˆå§‹æç¤º
if not st.session_state.messages:
    with st.chat_message("assistant"):
        st.write("æ‚¨å¥½ï¼æˆ‘æ˜¯å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·é€‰æ‹©æ¨¡å‹å’ŒåŠŸèƒ½å¼€å§‹äº¤äº’ã€‚")